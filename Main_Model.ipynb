{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ConvLSTM2D, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from convGRU import ConvGRU\n",
    "import tensorflow_addons as tfa\n",
    "from Yogi_torch import Yogi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dữ liệu đầu vào"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa ảnh\n",
    "image_folder = r\"E:\\BacSon\\Fair_2024_ConvLSTM_ConvGRU\\data\"\n",
    "# image_folder = r\"E:\\BacSon\\Fair_2023_ARIMA_LSTM_GRU\\dataSet\\data_img\"\n",
    "\n",
    "# Đọc từng file ảnh\n",
    "image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển ảnh về ma trận ảnh Gray\n",
    "\n",
    "def matrix_images(image_folder, image_files):\n",
    "    matrix_img = []\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        matrix_img.append(image)\n",
    "\n",
    "    return matrix_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áp dụng Min-Max Scaling chuẩn hóa dữ liệu\n",
    "def min_max_scaling(data):\n",
    "    # Chuyển danh sách các mảng numpy thành một mảng numpy đa chiều\n",
    "    data_array = np.array(data)\n",
    "\n",
    "    # Tính giá trị min và max trên toàn bộ dữ liệu\n",
    "    data_min = np.min(data_array)\n",
    "    data_max = np.max(data_array)\n",
    "\n",
    "    # Áp dụng công thức Min-Max Scaling\n",
    "    scaled_data = (data_array - data_min) / (data_max - data_min)\n",
    "\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tạo nhãn cho dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo nhãn chuỗi dữ liệu với 4 ảnh liên tiếp từ dữ liệu hình ảnh\n",
    "def create_image_sequences(data, time_steps):\n",
    "    num_samples, height, width, channels = data.shape\n",
    "    num_frames = num_samples - time_steps\n",
    "    input_sequences = np.zeros((num_frames, time_steps, height, width, channels))\n",
    "    labels = np.zeros((num_frames, height, width, channels))  # Khởi tạo mảng label\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        input_sequences[i] = data[i:i+time_steps]\n",
    "        labels[i] = data[i+time_steps]  # Xác định label là frame tiếp theo\n",
    "\n",
    "    return input_sequences, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu\n",
    "def Split_Data(X_data, y_data):\n",
    "    size = int(len(X_data) * 0.8)\n",
    "    size_val = int((len(X_data) - size) / 2)\n",
    "\n",
    "    X_train = X_data[:size]\n",
    "    X_val = X_data[size:size + size_val]\n",
    "    X_test = X_data[-size_val:]\n",
    "\n",
    "    y_train = y_data[:size]\n",
    "    y_val = y_data[size:size + size_val]\n",
    "    y_test = y_data[- size_val:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mô hình ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_lstm(X_train, y_train, X_val, y_val, time_step, optimizer, save_best_model, epochs):\n",
    "    height, width, channels = X_train.shape[2:]\n",
    "\n",
    "    # Xây dựng mô hình ConvLSTM\n",
    "    input_lstm = (time_step, height, width, channels)\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), input_shape=input_lstm, padding='same', \n",
    "                              activation=\"tanh\", return_sequences=True))\n",
    "    model_lstm.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), padding='same', activation=\"tanh\", return_sequences=True))\n",
    "    model_lstm.add(ConvLSTM2D(filters=1, kernel_size=(3, 3), padding='same', activation=\"tanh\"))\n",
    "\n",
    "    # Compile mô hình\n",
    "    model_lstm.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Dừng sớm\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    # Tạo thư mục nếu chưa tồn tại\n",
    "    os.makedirs(os.path.dirname(save_best_model), exist_ok=True)\n",
    "\n",
    "    # Lưu lại model tốt nhất\n",
    "    model_checkpoint = ModelCheckpoint(save_best_model, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "    # Training model\n",
    "    history = model_lstm.fit(X_train, y_train,\n",
    "                    batch_size = 4,\n",
    "                    epochs = epochs, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n",
    "    \n",
    "    return model_lstm, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mô hình Bi-ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_BiLSTM(X_train, y_train, X_val, y_val, time_step, optimizer, save_best_model, epochs):\n",
    "    height, width, channels = X_train.shape[2:]\n",
    "\n",
    "    # Xây dựng mô hình ConvLSTM\n",
    "    input_bilstm = (time_step, height, width, channels)\n",
    "    model_bilstm = Sequential()\n",
    "    model_bilstm.add(Bidirectional(ConvLSTM2D(filters=16, kernel_size=(3, 3), input_shape=input_bilstm, \n",
    "                                              padding='same', activation=\"tanh\", return_sequences=True)))\n",
    "    model_bilstm.add(Bidirectional(ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', activation=\"tanh\", return_sequences=True)))\n",
    "    model_bilstm.add(Bidirectional(ConvLSTM2D(filters=1, kernel_size=(3, 3), padding='same', activation=\"tanh\")))\n",
    "\n",
    "    # Compile mô hình\n",
    "    model_bilstm.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Dừng sớm\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "    # Tạo thư mục nếu chưa tồn tại\n",
    "    os.makedirs(os.path.dirname(save_best_model), exist_ok=True)\n",
    "\n",
    "    # Lưu lại model tốt nhất\n",
    "    model_checkpoint = ModelCheckpoint(save_best_model, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "    # Training model\n",
    "    history = model_bilstm.fit(X_train, y_train,\n",
    "                                batch_size = 4,\n",
    "                                epochs = epochs, \n",
    "                                validation_data=(X_val, y_val),\n",
    "                                callbacks=[early_stopping, model_checkpoint])\n",
    "    \n",
    "    return model_bilstm, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mô hình ConvGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_gru(X_train):\n",
    "    # Các tham số đầu vào\n",
    "    input_size = (X_train.shape[-2:])\n",
    "    channels = X_train.shape[2]\n",
    "    num_layers = 3\n",
    "    hidden_dim = [16, 128, 1]\n",
    "    kernel_size = [(5, 5), (3, 3), (5, 5)]\n",
    "    activation = torch.nn.ReLU\n",
    "\n",
    "    # Xây dựng mô hình\n",
    "    model_GRU = ConvGRU(input_size=input_size, input_dim=channels,\n",
    "                        hidden_dim=hidden_dim, kernel_size=kernel_size, num_layers=num_layers,\n",
    "                        dtype=torch.FloatTensor,\n",
    "                        batch_first=True,\n",
    "                        bias=True,\n",
    "                        return_all_layers=False,\n",
    "                        activation=activation)\n",
    "    \n",
    "    return model_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def save_model_to_hdf5(model, file_path):\n",
    "    with h5py.File(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.create_dataset(name, data=param.data.cpu().numpy())\n",
    "\n",
    "def train_ConvGRU(model, optimizer, train_dataloader, val_dataloader, best_model_path, num_epochs):\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for X_batch, y_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(X_batch)\n",
    "            output_last_layer = outputs[-1]\n",
    "            loss = criterion(output_last_layer, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        train_loss_epoch.append(avg_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_dataloader:\n",
    "                outputs, _ = model(X_batch)\n",
    "                output_last_layer = outputs[-1]\n",
    "                val_loss = criterion(output_last_layer, y_batch)\n",
    "                total_val_loss += val_loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "        val_loss_epoch.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_model_to_hdf5(model, best_model_path)\n",
    "            \n",
    "    history_model = {\"loss\" : train_loss_epoch, \"val_loss\" : val_loss_epoch}\n",
    "    return model, history_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá và Test mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biểu đồ train_loss và val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_model(history):\n",
    "    # Kiểm tra loại của history để trích xuất giá trị loss phù hợp\n",
    "    if isinstance(history, dict):\n",
    "        train_loss = history['loss']\n",
    "        val_loss = history['val_loss']\n",
    "    else:\n",
    "        train_loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_loss, linestyle='-', label='Train loss')\n",
    "    plt.plot(val_loss, linestyle='-', label='Val loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train loss và Val loss của mô hình')\n",
    "    plt.yscale('log')  # Scale y-axis to logarithmic scale\n",
    "    plt.legend()  # Thêm nhãn chú thích\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So sánh chọn mô hình tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tập test\n",
    "def Compare_Adam_Yogi(model_Adam, model_Yogi, X_val, y_val):\n",
    "    loss1 = model_Adam.evaluate(X_val, np.array(y_val))\n",
    "    print(f'Test loss: {loss1}')\n",
    "\n",
    "    loss2 = model_Yogi.evaluate(X_val, np.array(y_val))\n",
    "    print(f'Test loss: {loss2}')\n",
    "\n",
    "    if loss1 < loss2:\n",
    "        print(\"Best Model Adam\")\n",
    "        model = model_Adam\n",
    "    else:\n",
    "        print(\"Best Model YoGi\")\n",
    "        model = model_Yogi\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_hdf5(file_path, model):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in f:\n",
    "                param_data = torch.tensor(f[name][:])\n",
    "                param.data.copy_(param_data)\n",
    "            else:\n",
    "                print(f\"Không tìm thấy {name} trong file HDF5.\")\n",
    "    return model\n",
    "\n",
    "def loss_model(X_train_gru, model_path, val_dataloader):\n",
    "    model_eval = conv_gru(X_train_gru)\n",
    "    # model_eval.load_state_dict(best_model_name)\n",
    "    model_eval = load_model_from_hdf5(model_path, model_eval)\n",
    "    model_eval.eval()\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # Tính toán tổng loss trên tập validation\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            outputs, _ = model_eval(X_batch)\n",
    "            output_last_layer = outputs[-1]\n",
    "            val_loss = criterion(output_last_layer, y_batch)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    # Tính toán average validation loss\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "def Compare_Adam_Yogi_GRU(X_train_gru, model_path_Adam, model_path_Yogi, val_dataloader):\n",
    "    loss_Adam = loss_model(X_train_gru, model_path_Adam, val_dataloader)\n",
    "    loss_Yogi = loss_model(X_train_gru, model_path_Yogi, val_dataloader)\n",
    "\n",
    "    if loss_Adam < loss_Yogi:\n",
    "        print(\"Best Model Adam\")\n",
    "        best_model = model_path_Adam\n",
    "    else:\n",
    "        print(\"Best Model YoGi\")\n",
    "        best_model = model_path_Yogi\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dự đoán "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    # Dự đoán ảnh mới\n",
    "    predicted = model.predict(X_test)\n",
    "    predicted_images = np.array(predicted)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Đánh giá MSE MAE R^2\n",
    "    mse = mean_squared_error(y_test.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    mae = mean_absolute_error(y_test.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    r2 = r2_score(y_test.flatten(), predicted_images.flatten())\n",
    "    print(\"R-squared (R2) Score:\", r2)\n",
    "\n",
    "    # Hiển thị các ảnh dự đoán\n",
    "    fig, axs = plt.subplots(1, len(predicted_images), figsize=(15, 25))\n",
    "    for i in range(len(predicted_images)):\n",
    "        axs[i].imshow(predicted_images[i])  # Hiển thị ảnh cuối cùng trong mỗi mẫu dự đoán\n",
    "        axs[i].set_title(f\"Ảnh dự đoán {i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_BiConvLSTM(model, X_test, y_test):\n",
    "    # Dự đoán ảnh mới\n",
    "    predicted = model.predict(X_test)\n",
    "    predicted_images = np.mean(predicted, axis=-1, keepdims=True)  # Tính trung bình hai kênh màu\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Đánh giá MSE MAE R^2\n",
    "    mse = mean_squared_error(y_test.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    mae = mean_absolute_error(y_test.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    r2 = r2_score(y_test.flatten(), predicted_images.flatten())\n",
    "    print(\"R-squared (R2) Score:\", r2)\n",
    "\n",
    "    # Hiển thị các ảnh dự đoán\n",
    "    fig, axs = plt.subplots(1, len(predicted_images), figsize=(15, 25))\n",
    "    for i in range(len(predicted_images)):\n",
    "        axs[i].imshow(predicted_images[i])  # Hiển thị ảnh cuối cùng trong mỗi mẫu dự đoán\n",
    "        axs[i].set_title(f\"Ảnh dự đoán {i+1}\")\n",
    "    plt.show()\n",
    "\n",
    "    return predicted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_ConvGRU(X_train_gru, best_model_path, test_dataloader, y_test_gru):\n",
    "    model_eval = conv_gru(X_train_gru)\n",
    "    model_eval = load_model_from_hdf5(best_model_path, model_eval)\n",
    "    model_eval.eval()\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            outputs, _ = model_eval(X_batch)\n",
    "            output_last_image = outputs[-1][:, -1, ...]\n",
    "            predictions.append(output_last_image.cpu().numpy())\n",
    "\n",
    "    predicted_images = np.concatenate(predictions)\n",
    "    predicted_images = np.squeeze(predicted_images)\n",
    "\n",
    "    mse = mean_squared_error(y_test_gru.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    mae = mean_absolute_error(y_test_gru.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    r2 = r2_score(y_test_gru.flatten(), predicted_images.flatten())\n",
    "    print(\"R-squared (R2) Score:\", r2)\n",
    "\n",
    "    fig, axs = plt.subplots(1, min(len(predicted_images), 5), figsize=(15, 25))\n",
    "    for i in range(min(len(predicted_images), 5)):\n",
    "        axs[i].imshow(predicted_images[i])\n",
    "        axs[i].set_title(f\"Ảnh dự đoán {i+1}\")\n",
    "    plt.show()\n",
    "\n",
    "    return predicted_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chạy các mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn bị đầu vào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu ảnh\n",
    "data_img = matrix_images(image_folder, image_files)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "data_scaler = min_max_scaling(data_img)\n",
    "data_lstm = np.expand_dims(data_scaler, axis=-1)\n",
    "\n",
    "# Tạo chuỗi dữ liệu với 4 ảnh liên tiếp từ dữ liệu hình ảnh\n",
    "epochs = 200\n",
    "time_step = 4\n",
    "X_data, y_data = create_image_sequences(data_lstm, time_step)\n",
    "\n",
    "# Chia dữ liệu\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = Split_Data(X_data, y_data)\n",
    "\n",
    "# Kiểm tra kích thước của X_train\n",
    "print(\"Kích thước của X_train:\", X_train.shape)\n",
    "print(\"Kích thước của X_val:\", X_val.shape)\n",
    "print(\"Kích thước của X_test:\", X_test.shape)\n",
    "\n",
    "print(\"Kích thước của y_train:\", y_train.shape)\n",
    "print(\"Kích thước của y_val:\", y_val.shape)\n",
    "print(\"Kích thước của y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo chuỗi dữ liệu với 4 ảnh liên tiếp từ dữ liệu hình ảnh\n",
    "data_gru = np.expand_dims(data_scaler, axis=1)\n",
    "X_data_gru, y_data_gru = create_image_sequences(data_gru, time_step)\n",
    "\n",
    "# Chia dữ liệu\n",
    "X_train_gru, y_train_gru, X_val_gru, y_val_gru, X_test_gru, y_test_gru = Split_Data(X_data_gru, y_data_gru)\n",
    "\n",
    "# Kiểm tra kích thước của X_train\n",
    "print(\"Kích thước của X_train:\", X_train_gru.shape)\n",
    "print(\"Kích thước của X_val:\", X_val_gru.shape)\n",
    "print(\"Kích thước của X_test:\", X_test_gru.shape)\n",
    "\n",
    "print(\"Kích thước của y_train:\", y_train_gru.shape)\n",
    "print(\"Kích thước của y_val:\", y_val_gru.shape)\n",
    "print(\"Kích thước của y_test:\", y_test_gru.shape)\n",
    "\n",
    "# Chuyển đổi các mảng thành các tensor\n",
    "X_train_tensor = torch.tensor(X_train_gru, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_gru, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_gru, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_gru, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_gru, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_gru, dtype=torch.float32)\n",
    "\n",
    "# Tạo DataLoader cho training and validation\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_dataloader = DataLoader(val_dataset)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mô hình ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ConvLSTM bằng Adam\n",
    "optimizer_ConvLSTM_Adam = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "save_model_ConvLSTM_Adam = './KetQua/ConvLSTM/best_model_ConvLSTM_Adam.hdf5'\n",
    "model_ConvLSTM_Adam, history_ConvLSTM_Adam = conv_lstm(X_train, y_train, X_val, y_val, \n",
    "                                                       time_step, \n",
    "                                                       optimizer_ConvLSTM_Adam, \n",
    "                                                       save_model_ConvLSTM_Adam,\n",
    "                                                       epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_model(history_ConvLSTM_Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ConvLSTM bằng Yogi\n",
    "optimizer_ConvLSTM_Yogi = tfa.optimizers.Yogi(learning_rate=1e-3)\n",
    "save_model_ConvLSTM_Yogi = './KetQua/ConvLSTM/best_model_ConvLSTM_Yogi.hdf5'\n",
    "model_ConvLSTM_Yogi, history_ConvLSTM_Yogi = conv_lstm(X_train, y_train, X_val, y_val, \n",
    "                                                       time_step, \n",
    "                                                       optimizer_ConvLSTM_Yogi, \n",
    "                                                       save_model_ConvLSTM_Yogi,\n",
    "                                                       epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_model(history_ConvLSTM_Yogi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định mô hình tốt nhất\n",
    "best_model_ConvLTSM = Compare_Adam_Yogi(model_ConvLSTM_Adam, model_ConvLSTM_Yogi, X_val, y_val)\n",
    "\n",
    "# Dự đoán trên model tốt nhất\n",
    "test_model(best_model_ConvLTSM, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mô hình Bi-ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Bi-ConvLSTM bằng Adam\n",
    "optimizer_BiConvLSTM_Adam = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "save_model_BiConvLSTM_Adam = './KetQua/Bi-ConvLSTM/best_model_Bi-ConvLSTM_Adam.hdf5'\n",
    "model_BiConvLSTM_Adam, history_BiConvLSTM_Adam = conv_BiLSTM(X_train, y_train, X_val, y_val, \n",
    "                                                            time_step, \n",
    "                                                            optimizer_BiConvLSTM_Adam, \n",
    "                                                            save_model_BiConvLSTM_Adam,\n",
    "                                                            epochs)\n",
    "plot_loss_model(history_BiConvLSTM_Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Bi-ConvLSTM bằng Yogi\n",
    "optimizer_BiConvLSTM_Yogi = tfa.optimizers.Yogi(learning_rate=1e-3)\n",
    "save_model_BiConvLSTM_Yogi = './KetQua/Bi-ConvLSTM/best_model_Bi-ConvLSTM_Yogi.hdf5'\n",
    "model_BiConvLSTM_Yogi, history_BiConvLSTM_Yogi = conv_BiLSTM(X_train, y_train, X_val, y_val, \n",
    "                                                            time_step, \n",
    "                                                            optimizer_BiConvLSTM_Yogi, \n",
    "                                                            save_model_BiConvLSTM_Yogi,\n",
    "                                                            epochs)\n",
    "plot_loss_model(history_BiConvLSTM_Yogi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định mô hình tốt nhất\n",
    "best_model_BiConvLTSM = Compare_Adam_Yogi(model_BiConvLSTM_Adam, model_BiConvLSTM_Yogi, X_val, y_val)\n",
    "\n",
    "# Dự đoán trên model tốt nhất\n",
    "predicted_images_BiConvLTSM = test_model_BiConvLSTM(best_model_BiConvLTSM, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mô hình GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ConvGRU bằng Adam\n",
    "model_ConvGRU_Adam = conv_gru(X_train_gru)\n",
    "optimizer_ConvGRU_Adam = torch.optim.Adam(model_ConvGRU_Adam.parameters(), lr=1e-3)\n",
    "save_model_ConvGRU_Adam = './KetQua/ConvGRU/best_model_ConvGRU_Adam.hdf5'\n",
    "\n",
    "best_model_ConvGRU_Adam, history_ConvGRU_Adam = train_ConvGRU(model_ConvGRU_Adam, \n",
    "                                                            optimizer_ConvGRU_Adam, \n",
    "                                                            train_dataloader, \n",
    "                                                            val_dataloader, \n",
    "                                                            save_model_ConvGRU_Adam,\n",
    "                                                            epochs)\n",
    "\n",
    "plot_loss_model(history_ConvGRU_Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training ConvGRU bằng Yogi\n",
    "model_ConvGRU_Yogi = conv_gru(X_train_gru)\n",
    "optimizer_ConvGRU_Yogi = Yogi(model_ConvGRU_Yogi.parameters(), lr=1e-3)\n",
    "save_model_ConvGRU_Yogi = './KetQua/ConvGRU/best_model_ConvGRU_Yogi.hdf5'\n",
    "\n",
    "best_model_ConvGRU_Yogi, history_ConvGRU_Yogi = train_ConvGRU(model_ConvGRU_Yogi, \n",
    "                                                            optimizer_ConvGRU_Yogi, \n",
    "                                                            train_dataloader, \n",
    "                                                            val_dataloader,\n",
    "                                                            save_model_ConvGRU_Yogi,\n",
    "                                                            epochs)\n",
    "plot_loss_model(history_ConvGRU_Yogi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định mô hình tốt nhất\n",
    "best_model_path_ConvGRU = Compare_Adam_Yogi_GRU(X_train_gru, save_model_ConvGRU_Adam, save_model_ConvGRU_Yogi, val_dataloader)\n",
    "\n",
    "# Dự đoán trên model tốt nhất\n",
    "predictions = test_model_ConvGRU(X_train_gru, best_model_path_ConvGRU, test_dataloader, y_test_gru)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
