{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ductr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ductr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\ductr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from convGRU import ConvGRU\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Yogi_torch import Yogi\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow_addons as tfa\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import h5py\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dữ liệu đầu vào"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa ảnh\n",
    "image_folder = r\"E:\\BacSon\\Fair_2024_ConvLSTM_ConvGRU\\data\"\n",
    "\n",
    "# Đọc từng file ảnh\n",
    "image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển ảnh về ma trận ảnh Gray\n",
    "\n",
    "def matrix_images(image_folder, image_files):\n",
    "    matrix_img = []\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        matrix_img.append(image)\n",
    "\n",
    "    return matrix_img\n",
    "\n",
    "data = matrix_images(image_folder, image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áp dụng Min-Max Scaling chuẩn hóa dữ liệu\n",
    "def min_max_scaling(data):\n",
    "    # Chuyển danh sách các mảng numpy thành một mảng numpy đa chiều\n",
    "    data_array = np.array(data)\n",
    "\n",
    "    # Tính giá trị min và max trên toàn bộ dữ liệu\n",
    "    data_min = np.min(data_array)\n",
    "    data_max = np.max(data_array)\n",
    "\n",
    "    # Áp dụng công thức Min-Max Scaling\n",
    "    scaled_data = (data_array - data_min) / (data_max - data_min)\n",
    "\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = min_max_scaling(data)\n",
    "data = np.expand_dims(data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_sequences(data, time_steps):\n",
    "    num_samples, height, width, channels = data.shape\n",
    "    num_frames = num_samples - time_steps\n",
    "    input_sequences = np.zeros((num_frames, time_steps, height, width, channels))\n",
    "    labels = np.zeros((num_frames, height, width, channels))  # Khởi tạo mảng label\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        input_sequences[i] = data[i:i+time_steps]\n",
    "        labels[i] = data[i+time_steps]  # Xác định label là frame tiếp theo\n",
    "\n",
    "    return input_sequences, labels\n",
    "\n",
    "# Tạo chuỗi dữ liệu với 4 ảnh liên tiếp từ dữ liệu hình ảnh\n",
    "time_step = 4\n",
    "X_data, y_data = create_image_sequences(data, time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu\n",
    "size = int(len(X_data) * 0.8)\n",
    "size_val = int((len(X_data) - size) / 2)\n",
    "\n",
    "X_train = X_data[:size]\n",
    "X_val = X_data[size:size + size_val]\n",
    "X_test = X_data[-size_val:]\n",
    "\n",
    "y_train = y_data[:size]\n",
    "y_val = y_data[size:size + size_val]\n",
    "y_test = y_data[- size_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước của X_train: (48, 4, 1, 150, 150)\n",
      "Kích thước của X_val: (6, 4, 1, 150, 150)\n",
      "Kích thước của X_test: (6, 4, 1, 150, 150)\n",
      "Kích thước của y_train: (48, 1, 150, 150)\n",
      "Kích thước của y_val: (6, 1, 150, 150)\n",
      "Kích thước của y_test: (6, 1, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra kích thước của X_train\n",
    "print(\"Kích thước của X_train:\", X_train.shape)\n",
    "print(\"Kích thước của X_val:\", X_val.shape)\n",
    "print(\"Kích thước của X_test:\", X_test.shape)\n",
    "\n",
    "print(\"Kích thước của y_train:\", y_train.shape)\n",
    "print(\"Kích thước của y_val:\", y_val.shape)\n",
    "print(\"Kích thước của y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mô hình GA-ConvGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tinh chỉnh các thông số đầu vào cho mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi các mảng thành các tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Tạo DataLoader cho training and validation\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_dataloader = DataLoader(val_dataset)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Câu trúc mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_gru(X_train, hidden_dim, kernel_size, activation_function):\n",
    "    # Các tham số đầu vào\n",
    "    input_size = (X_train.shape[-2:])\n",
    "    channels = X_train.shape[2]\n",
    "    num_layers = 3\n",
    "\n",
    "    # Xây dựng mô hình\n",
    "    model_GRU = ConvGRU(input_size=input_size, \n",
    "                        input_dim=channels,\n",
    "                        hidden_dim=hidden_dim, \n",
    "                        kernel_size=kernel_size, \n",
    "                        num_layers=num_layers,\n",
    "                        dtype=torch.FloatTensor,\n",
    "                        batch_first=True,\n",
    "                        bias=True,\n",
    "                        return_all_layers=False,\n",
    "                        activation=activation_function)\n",
    "    \n",
    "    return model_GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Áp dụng GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def save_model_to_hdf5(model, file_path):\n",
    "    with h5py.File(file_path, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.create_dataset(name, data=param.data.cpu().numpy())\n",
    "\n",
    "# Hàm mục tiêu cho mô hình\n",
    "def fitness_function(X_train, train_dataloader, val_dataloader, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, \n",
    "                     kernel_size3, activation_function, optimizer, num_epochs=1, save_path_model = \"\"):\n",
    "    # Gọi mô hình\n",
    "    hidden_dim = [hidden_dim1, hidden_dim2, 1]\n",
    "    kernel_size = [kernel_size1, kernel_size2, kernel_size3]\n",
    "    model = conv_gru(X_train, hidden_dim, kernel_size, activation_function)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for X_batch, y_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(X_batch)\n",
    "            output_last_layer = outputs[-1]\n",
    "            loss = criterion(output_last_layer, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        train_loss_epoch.append(avg_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_dataloader:\n",
    "                outputs, _ = model(X_batch)\n",
    "                output_last_layer = outputs[-1]\n",
    "                val_loss = criterion(output_last_layer, y_batch)\n",
    "                total_val_loss += val_loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "        val_loss_epoch.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            \n",
    "    # lưu lại model tốt nhất\n",
    "    if save_path_model:\n",
    "        os.makedirs(os.path.dirname(save_path_model), exist_ok=True)\n",
    "        save_model_to_hdf5(model, save_path_model)\n",
    "        history_model = {\"loss\" : train_loss_epoch, \"val_loss\" : val_loss_epoch}\n",
    "        \n",
    "        return best_val_loss, model, history_model\n",
    "    else:\n",
    "        return best_val_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đánh giá cá thể trong quần thể\n",
    "def evaluate(individual):\n",
    "    hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation = individual\n",
    "    num_epochs = 50\n",
    "\n",
    "    print(\"Train Adam\")\n",
    "    optimizer_Adam = torch.optim.Adam(conv_gru(X_train, \n",
    "                                               [hidden_dim1, hidden_dim2, 1], \n",
    "                                               [kernel_size1, kernel_size2, kernel_size3], activation).parameters(), \n",
    "                                               lr = 1e-3)\n",
    "    val_loss_adam, _ = fitness_function(X_train, train_dataloader, val_dataloader, \n",
    "                                        hidden_dim1, hidden_dim2, \n",
    "                                        kernel_size1, kernel_size2, kernel_size3, activation,\n",
    "                                        optimizer_Adam, num_epochs=num_epochs)\n",
    "    return val_loss_adam,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa hàm tạo quần thể\n",
    "def create_population(n, hidden_dim1, hidden_dim2, kernel_size_func1, kernel_size_func2, kernel_size_func3, activation):\n",
    "    population = [creator.Individual([hidden_dim1(), hidden_dim2(), kernel_size_func1(), kernel_size_func2(), \n",
    "                                      kernel_size_func3(), activation()]) for _ in range(n)]\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đột biến cá thể\n",
    "def mutate_individual(individual, indpb):\n",
    "    if random.random() < indpb:\n",
    "        individual[0] = random.choice([16, 32, 64, 128])  # filters1\n",
    "    if random.random() < indpb:\n",
    "        individual[1] = random.choice([16, 32, 64, 128])  # filters2\n",
    "    if random.random() < indpb:\n",
    "        individual[2] = random.choice([(3, 3), (5, 5), (7, 7)])  # kernel_size1\n",
    "    if random.random() < indpb:\n",
    "        individual[3] = random.choice([(3, 3), (5, 5), (7, 7)])  # kernel_size2\n",
    "    if random.random() < indpb:\n",
    "        individual[4] = random.choice([(3, 3), (5, 5), (7, 7)])  # kernel_size3\n",
    "    if random.random() < indpb:\n",
    "        individual[5] = random.choice([nn.Tanh, nn.ReLU, nn.Sigmoid])  # activation\n",
    "    return individual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Số lượng quần thể ban đầu\n",
    "num_populations = 1\n",
    "# Số lượng cá thể trong quần thể ban đầu\n",
    "individuals = 2\n",
    "# Quá trình lai ghép và đột biến\n",
    "num_generations = 0\n",
    "\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quần thể ban đầu 1:\n",
      "Cá thể thứ 0: [64, 128, (7, 7), (7, 7), (3, 3), <class 'torch.nn.modules.activation.ReLU'>]\n",
      "Cá thể thứ 1: [16, 64, (3, 3), (7, 7), (5, 5), <class 'torch.nn.modules.activation.Sigmoid'>]\n",
      "\n",
      "Train Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ductr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 1, 150, 150])) that is different to the input size (torch.Size([1, 4, 1, 150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.04539739204725871, Val Loss: 0.04052261325220267\n",
      "Train Adam\n",
      "Epoch 1/1, Train Loss: 0.12163971721505125, Val Loss: 0.12038123980164528\n",
      "Cá thể tốt nhất trong quần thể thứ 1: [64, 128, (7, 7), (7, 7), (3, 3), <class 'torch.nn.modules.activation.ReLU'>] ban đầu\n",
      "\n",
      "Bắt đầu quá trình lai ghép và đột biến...\n",
      "\n",
      "Cá thể tốt nhất cuối cùng:\n",
      "[64, 128, (7, 7), (7, 7), (3, 3), <class 'torch.nn.modules.activation.ReLU'>]\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo hàm mục tiêu\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "# Khởi tạo toolbox\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_filters\", random.choice, [16, 32, 64, 128])\n",
    "toolbox.register(\"attr_kernel_size\", random.choice, [(3, 3), (5, 5), (7, 7)])\n",
    "toolbox.register(\"attr_activation\", random.choice, [nn.Tanh, nn.ReLU, nn.Sigmoid])\n",
    "# toolbox.register(\"attr_activation\", random.choice, [\"tanh\", \"relu\", \"sigmoid\"])\n",
    "\n",
    "# Đăng ký cá thể và quần thể\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual, \n",
    "                 (toolbox.attr_filters, toolbox.attr_filters, \n",
    "                  toolbox.attr_kernel_size, toolbox.attr_kernel_size, \n",
    "                  toolbox.attr_kernel_size, toolbox.attr_activation), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Đăng ký các toán tử lai ghép, đột biến và chọn lọc\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", mutate_individual, indpb=0.15)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "# Tạo và in quần thể ban đầu\n",
    "populations = []\n",
    "for i in range(num_populations):\n",
    "    population = create_population(individuals, toolbox.attr_filters, toolbox.attr_filters, \n",
    "                                   toolbox.attr_kernel_size, toolbox.attr_kernel_size, toolbox.attr_kernel_size, \n",
    "                                   toolbox.attr_activation)\n",
    "    populations.append(population)\n",
    "    print(f\"Quần thể ban đầu {i + 1}:\")\n",
    "    for j, ind in enumerate(population):\n",
    "        print(f\"Cá thể thứ {j}: {ind}\")\n",
    "    print()\n",
    "\n",
    "# Đánh giá fitness và chọn lọc cá thể tốt nhất cho mỗi quần thể ban đầu\n",
    "best_individuals = []\n",
    "for population in populations:\n",
    "    fits = toolbox.map(toolbox.evaluate, population)\n",
    "    for fit, ind in zip(fits, population):\n",
    "        ind.fitness.values = fit\n",
    "    best_ind = min(population, key=lambda ind: ind.fitness.values)\n",
    "    best_individuals.append(best_ind)\n",
    "    print(f\"Cá thể tốt nhất trong quần thể thứ {populations.index(population) + 1}: {best_ind} ban đầu\")\n",
    "print()\n",
    "\n",
    "# Quá trình lai ghép và đột biến\n",
    "print(\"Bắt đầu quá trình lai ghép và đột biến...\")\n",
    "print()\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    # Tạo quần thể con bằng cách lai ghép và đột biến từ các cá thể tốt nhất\n",
    "    offspring = algorithms.varAnd(best_individuals, toolbox, cxpb=0.7, mutpb=0.15)\n",
    "    print(f\"Quần thể con F{gen + 1} đã được tiến hóa:\")\n",
    "    for i, ind in enumerate(offspring):\n",
    "        print(f\"Cá thể thứ {i + 1}: {ind}\")\n",
    "\n",
    "    # Đánh giá fitness của quần thể con\n",
    "    fits = list(map(toolbox.evaluate, offspring))\n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        ind.fitness.values = fit\n",
    "    best_ind = min(offspring, key=lambda ind: ind.fitness.values)\n",
    "    best_individuals.append(best_ind)\n",
    "    print(f\"Cá thể tốt nhất trong quần thể con F{gen + 1}: {best_ind}\")\n",
    "\n",
    "    # Chọn lọc cá thể để tạo quần thể mới cho thế hệ tiếp theo\n",
    "    best_individuals = toolbox.select(best_individuals, k=4)\n",
    "    print()\n",
    "\n",
    "# In ra cá thể tốt nhất cuối cùng\n",
    "best_ind = min(best_individuals, key=lambda ind: ind.fitness.values)\n",
    "print(\"Cá thể tốt nhất cuối cùng:\")\n",
    "print(best_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đánh giá và test mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biểu đồ train_loss và val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_model_ConvGRU(history):\n",
    "    # Trích xuất giá trị loss trên tập huấn luyện và kiểm tra\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_loss, linestyle='-', label='Train loss')\n",
    "    plt.plot(val_loss, linestyle='-', label='Val loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train loss và Val loss của mô hình')\n",
    "    plt.yscale('log')  # Scale y-axis to logarithmic scale\n",
    "    plt.legend()  # Thêm nhãn chú thích\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các tham số từ cá thể tốt nhất và training mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 128 (7, 7) (7, 7) (3, 3) <class 'torch.nn.modules.activation.ReLU'>\n"
     ]
    }
   ],
   "source": [
    "hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation = best_ind\n",
    "\n",
    "print(hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Adam = conv_gru(X_train, [hidden_dim1, hidden_dim2, 1], [kernel_size1, kernel_size2, kernel_size3], activation)\n",
    "optimizer_Adam = torch.optim.Adam(model_Adam.parameters(), lr=1e-3)\n",
    "save_model_ConvGRU_Adam = './KetQua/ConvGRU/best_model_ConvGRU_Adam.hdf5'\n",
    "\n",
    "val_loss_Adam, best_model_Adam, history_model_Adam = fitness_function(X_train, train_dataloader, val_dataloader, \n",
    "                                                                      hidden_dim1, hidden_dim2, \n",
    "                                                                      kernel_size1, kernel_size2, kernel_size3, \n",
    "                                                                      activation,\n",
    "                                                                      optimizer_Adam, \n",
    "                                                                      num_epochs=epochs, \n",
    "                                                                      save_path_model = save_model_ConvGRU_Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_model_ConvGRU(history_model_Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Yogi = conv_gru(X_train, [hidden_dim1, hidden_dim2, 1], [kernel_size1, kernel_size2, kernel_size3], activation)\n",
    "optimizer_Yogi = Yogi(model_Yogi.parameters(), lr=1e-3)\n",
    "save_model_ConvGRU_Yogi = './KetQua/ConvGRU/best_model_ConvGRU_Yogi.hdf5'\n",
    "\n",
    "val_loss_Yogi, best_model_Yogi, history_model_Yogi = fitness_function(X_train, train_dataloader, val_dataloader, \n",
    "                                                                      hidden_dim1, hidden_dim2, \n",
    "                                                                      kernel_size1, kernel_size2, kernel_size3, \n",
    "                                                                      activation,\n",
    "                                                                      optimizer_Yogi, \n",
    "                                                                      num_epochs=epochs, \n",
    "                                                                      save_path_model = save_model_ConvGRU_Yogi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_model_ConvGRU(history_model_Yogi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_hdf5(file_path, model):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in f:\n",
    "                param_data = torch.tensor(f[name][:])\n",
    "                param.data.copy_(param_data)\n",
    "            else:\n",
    "                print(f\"Không tìm thấy {name} trong file HDF5.\")\n",
    "    return model\n",
    "\n",
    "# def loss_model(X_train_gru, best_model_path, val_dataloader):\n",
    "def loss_model(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, \n",
    "               activation, model_path, val_dataloader):\n",
    "    model_eval = conv_gru(X_train_gru, [hidden_dim1, hidden_dim2, 1], [kernel_size1, kernel_size2, kernel_size3], activation)\n",
    "    model_eval = load_model_from_hdf5(model_path, model_eval)\n",
    "    model_eval.eval()\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # Tính toán tổng loss trên tập validation\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_dataloader:\n",
    "            outputs, _ = model_eval(X_batch)\n",
    "            output_last_layer = outputs[-1]\n",
    "            val_loss = criterion(output_last_layer, y_batch)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    # Tính toán average validation loss\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "def Compare_Adam_Yogi_GRU(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation,\n",
    "                          model_path_Adam, model_path_Yogi, val_dataloader):\n",
    "    loss_Adam = loss_model(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation,\n",
    "                           model_path_Adam, val_dataloader)\n",
    "    loss_Yogi = loss_model(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation,\n",
    "                           model_path_Yogi, val_dataloader)\n",
    "    if loss_Adam < loss_Yogi:\n",
    "        print(\"Best Model Adam\")\n",
    "        best_model_path = model_path_Adam\n",
    "    else:\n",
    "        print(\"Best Model YoGi\")\n",
    "        best_model_path = model_path_Yogi\n",
    "\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (7) must match the size of tensor b (3) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model_path_ConvGRU \u001b[38;5;241m=\u001b[39m \u001b[43mCompare_Adam_Yogi_GRU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mhidden_dim1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mkernel_size1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43msave_model_ConvGRU_Adam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_ConvGRU_Yogi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 36\u001b[0m, in \u001b[0;36mCompare_Adam_Yogi_GRU\u001b[1;34m(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation, model_path_Adam, model_path_Yogi, val_dataloader)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCompare_Adam_Yogi_GRU\u001b[39m(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation,\n\u001b[0;32m     35\u001b[0m                           model_path_Adam, model_path_Yogi, val_dataloader):\n\u001b[1;32m---> 36\u001b[0m     loss_Adam \u001b[38;5;241m=\u001b[39m \u001b[43mloss_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_gru\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmodel_path_Adam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     loss_Yogi \u001b[38;5;241m=\u001b[39m loss_model(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation,\n\u001b[0;32m     39\u001b[0m                            model_path_Yogi, val_dataloader)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_Adam \u001b[38;5;241m<\u001b[39m loss_Yogi:\n",
      "Cell \u001b[1;32mIn[21], line 15\u001b[0m, in \u001b[0;36mloss_model\u001b[1;34m(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, activation, model_path, val_dataloader)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_model\u001b[39m(X_train_gru, hidden_dim1, hidden_dim2, kernel_size1, kernel_size2, kernel_size3, \n\u001b[0;32m     13\u001b[0m                activation, model_path, val_dataloader):\n\u001b[0;32m     14\u001b[0m     model_eval \u001b[38;5;241m=\u001b[39m conv_gru(X_train_gru, [hidden_dim1, hidden_dim2, \u001b[38;5;241m1\u001b[39m], [kernel_size1, kernel_size2, kernel_size3], activation)\n\u001b[1;32m---> 15\u001b[0m     model_eval \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     model_eval\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     18\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(file_path, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     param_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(f[name][:])\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKhông tìm thấy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trong file HDF5.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (3) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "best_model_path_ConvGRU = Compare_Adam_Yogi_GRU(X_train, \n",
    "                                                hidden_dim1, hidden_dim2, \n",
    "                                                kernel_size1, kernel_size2, kernel_size3, \n",
    "                                                activation,\n",
    "                                                save_model_ConvGRU_Adam, save_model_ConvGRU_Yogi, \n",
    "                                                val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dự đoán và đánh giá mô hình trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_ConvGRU(X_train_gru, best_model_path, test_dataloader, y_test_gru):\n",
    "    model_eval = conv_gru(X_train_gru, [hidden_dim1, hidden_dim2, 1], [kernel_size1, kernel_size2, kernel_size3], activation)\n",
    "    model_eval = load_model_from_hdf5(best_model_path, model_eval)\n",
    "    model_eval.eval()\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            outputs, _ = model_eval(X_batch)\n",
    "            output_last_image = outputs[-1][:, -1, ...]\n",
    "            predictions.append(output_last_image.cpu().numpy())\n",
    "\n",
    "    predicted_images = np.concatenate(predictions)\n",
    "    predicted_images = np.squeeze(predicted_images)\n",
    "\n",
    "    mse = mean_squared_error(y_test_gru.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    mae = mean_absolute_error(y_test_gru.flatten(), predicted_images.flatten())\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    r2 = r2_score(y_test_gru.flatten(), predicted_images.flatten())\n",
    "    print(\"R-squared (R2) Score:\", r2)\n",
    "\n",
    "    fig, axs = plt.subplots(1, min(len(predicted_images), 5), figsize=(15, 25))\n",
    "    for i in range(min(len(predicted_images), 5)):\n",
    "        axs[i].imshow(predicted_images[i])\n",
    "        axs[i].set_title(f\"Ảnh dự đoán {i+1}\")\n",
    "    plt.show()\n",
    "\n",
    "    return predicted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên model tốt nhất\n",
    "test_model_ConvGRU(X_train, best_model_path_ConvGRU, test_dataloader, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
